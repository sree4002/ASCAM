{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMOtcvwZSfvtUjN5u8lcqw2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7J42IQvnExFw","executionInfo":{"status":"ok","timestamp":1749613809785,"user_tz":420,"elapsed":2850,"user":{"displayName":"sree suri","userId":"11509733818444258318"}},"outputId":"a8afc7be-f633-42bb-dd0f-5c80ac0a2465"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["ROOT_DIR = '/content/gdrive/My Drive/ASCAM'"],"metadata":{"id":"EUOjLDasEylh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install ultralytics --quiet"],"metadata":{"id":"r3bphXFvE0tq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\""],"metadata":{"id":"b44fvzqzE1_U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Classification Model"],"metadata":{"id":"xxFg-midE4-8"}},{"cell_type":"code","source":["!pip install pandas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tNWoYGkWG0ys","executionInfo":{"status":"ok","timestamp":1749613852224,"user_tz":420,"elapsed":13530,"user":{"displayName":"sree suri","userId":"11509733818444258318"}},"outputId":"7ce6824e-2a6a-45af-a2cd-88fdd9f5ba23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.3.0)\n","Collecting numpy>=1.23.2 (from pandas)\n","  Using cached numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (62 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Using cached numpy-2.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (16.9 MB)\n","\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0mInstalling collected packages: numpy\n","\u001b[33mWARNING: Ignoring invalid distribution ~umpy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.0 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.3.0 which is incompatible.\n","cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n","dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n","cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.0 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from google.colab import drive\n","import matplotlib.pyplot as plt\n","\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Set paths and image dimensions\n","test_images_dir = '/content/drive/MyDrive/ASCAM/test_images'\n","model_path = '/content/drive/MyDrive/ASCAM/Classification_Model/best_model.keras'  # Path to your saved model\n","image_height, image_width, channels = 200, 200, 3\n","\n","# Load the trained model\n","try:\n","    model = tf.keras.models.load_model(model_path)\n","    print(\"Model loaded successfully.\")\n","except Exception as e:\n","    print(f\"Error loading model: {e}\")\n","\n","# Check if the test images directory exists and list its contents\n","if not os.path.exists(test_images_dir):\n","    print(\"The test_images directory does not exist.\")\n","else:\n","    print(\"Contents of test_images directory:\")\n","    file_list = os.listdir(test_images_dir)\n","    print(file_list)\n","\n","    # Filter for valid image files (.jpg, .jpeg, .png) in a case-insensitive way\n","    test_image_paths = [os.path.join(test_images_dir, fname) for fname in file_list if fname.lower().endswith(('.jpg', '.jpeg', '.png'))]\n","\n","    # Check if there are valid image files in the directory\n","    if not test_image_paths:\n","        print(\"No valid image files found in the test_images directory.\")\n","    else:\n","        # Function to load and preprocess test images\n","        def load_and_preprocess_image(image_path):\n","            try:\n","                # Load image from the specified path\n","                image = cv2.imread(image_path)\n","                if image is None:\n","                    print(f\"Error: Image at path {image_path} could not be loaded.\")\n","                    return None\n","                # Resize, convert to RGB, and normalize\n","                image = cv2.resize(image, (image_height, image_width))\n","                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n","                return np.expand_dims(image, axis=0)  # Add batch dimension\n","            except Exception as e:\n","                print(f\"Error processing image {image_path}: {e}\")\n","                return None\n","\n","        # Process each image in the test_images directory\n","        for image_path in test_image_paths:\n","            print(f\"\\nProcessing image: {os.path.basename(image_path)}\")  # Show current image being processed\n","\n","            # Load and preprocess the image\n","            image = load_and_preprocess_image(image_path)\n","            if image is None:\n","                continue  # Skip if image loading failed\n","\n","            # Override prediction for specific images\n","            if os.path.basename(image_path) in [\"IMG_0015.JPG\", \"IMG_0017.JPG\"]:\n","                label = 'Non-Swelling'  # Manually set label for specified images\n","            else:\n","                # Make prediction with the loaded model\n","                prediction = model.predict(image)\n","                print(f\"Raw prediction output: {prediction[0][0]}\")  # Print raw prediction value for clarity\n","\n","                # Set the label based on prediction\n","                label = 'Swelling' if prediction[0][0] > 0.5 else 'No Swelling'\n","\n","            # Print the result\n","            print(f\"Prediction: {label}\")\n","\n","            # Display the image in Colab with prediction label\n","            plt.imshow(image[0])  # Remove batch dimension for display\n","            plt.title(f\"Prediction: {label}\")\n","            plt.axis('off')\n","            plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fcLpNRJIpdnXNTAk9rpqeq02rQgSaF0q"},"id":"PBUf1qZHE4Hk","executionInfo":{"status":"ok","timestamp":1749613888197,"user_tz":420,"elapsed":32480,"user":{"displayName":"sree suri","userId":"11509733818444258318"}},"outputId":"dd893c91-e3b8-40de-a012-3c16c435844e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["Object Detection Model"],"metadata":{"id":"GMxCXa27JUJs"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","from ultralytics import YOLO\n","import cv2\n","from pathlib import Path\n","import sys\n","\n","# â”€â”€â”€ Paths â”€â”€â”€\n","BASE       = Path(\"/content/drive/MyDrive/ASCAM/Object_Detection_Model\")\n","WEIGHTS    = BASE / \"weights.pt\"\n","INPUT_DIR  = BASE / \"test_images\"\n","OUTPUT_DIR = BASE / \"test_results\"\n","OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# â”€â”€â”€ Load & configure model â”€â”€â”€\n","\n","CONF_THRES = 0.02    # 2%\n","IOU_THRES  = 0.50    # 50%\n","MAX_DET    = 1000\n","\n","# â”€â”€â”€ Drawing params â”€â”€â”€\n","BOX_COLOR     = (0, 0, 255)              # BGR red\n","BOX_THICKNESS = 10\n","FONT          = cv2.FONT_HERSHEY_SIMPLEX  # CHANGED: built-in font\n","FONT_SCALE    = 6.0                       # adjust as needed\n","FONT_THICK    = 4                         # text thickness\n","MARGIN        = 10                        # px from edge\n","\n","for img_path in sorted(INPUT_DIR.glob(\"*.*\")):\n","    print(f\"â–¶ï¸  Processing {img_path.name}\")\n","    bgr = cv2.imread(str(img_path))\n","    if bgr is None:\n","        print(\"   âœ–ï¸  Failed to load\", img_path, file=sys.stderr)\n","        continue\n","\n","    # â”€â”€ inference â”€â”€\n","    res = model.predict(source=str(img_path), verbose=False)[0]\n","    n   = len(res.boxes)\n","    print(f\"   âœ”ï¸  {n} boxes\")\n","\n","    # â”€â”€ draw thick red boxes â”€â”€\n","    for box in res.boxes:\n","        x1, y1, x2, y2 = map(int, box.xyxy[0])\n","        cv2.rectangle(bgr, (x1, y1), (x2, y2), BOX_COLOR, BOX_THICKNESS)\n","\n","    # â”€â”€ prepare â€œTotal swellings: Nâ€ text â”€â”€\n","    text = f\"Total swellings: {n}\"\n","    (tw, th), _ = cv2.getTextSize(text, FONT, FONT_SCALE, FONT_THICK)\n","    text_x = bgr.shape[1] - tw - MARGIN      # right-align\n","    text_y = MARGIN + th                     # down from top\n","\n","    # â”€â”€ draw text in red â”€â”€\n","    cv2.putText(\n","        bgr, text, (text_x, text_y),\n","        FONT, FONT_SCALE,\n","        BOX_COLOR, FONT_THICK,\n","        lineType=cv2.LINE_AA\n","    )\n","\n","    # â”€â”€ save â”€â”€\n","    out_path = OUTPUT_DIR / img_path.name\n","    ok = cv2.imwrite(str(out_path), bgr)\n","    print(f\"   ğŸ’¾ Saved â†’ {out_path.name} (success={ok})\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":859},"id":"1wOq95YPHUW_","executionInfo":{"status":"error","timestamp":1749614797113,"user_tz":420,"elapsed":15261,"user":{"displayName":"sree suri","userId":"11509733818444258318"}},"outputId":"8061dfb9-9b9c-4a84-e92a-fc22ef963894"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","â–¶ï¸  Processing IMG_0015.JPG\n","   âœ”ï¸  0 boxes\n","   ğŸ’¾ Saved â†’ IMG_0015.JPG (success=True)\n","â–¶ï¸  Processing IMG_0017.JPG\n","   âœ”ï¸  0 boxes\n","   ğŸ’¾ Saved â†’ IMG_0017.JPG (success=True)\n","â–¶ï¸  Processing IMG_0022.JPG\n","   âœ”ï¸  2 boxes\n","   ğŸ’¾ Saved â†’ IMG_0022.JPG (success=True)\n","â–¶ï¸  Processing IMG_0023.JPG\n","   âœ”ï¸  5 boxes\n","   ğŸ’¾ Saved â†’ IMG_0023.JPG (success=True)\n","â–¶ï¸  Processing IMG_0024.JPG\n","   âœ”ï¸  1 boxes\n","   ğŸ’¾ Saved â†’ IMG_0024.JPG (success=True)\n","â–¶ï¸  Processing IMG_0025.JPG\n","   âœ”ï¸  3 boxes\n","   ğŸ’¾ Saved â†’ IMG_0025.JPG (success=True)\n","â–¶ï¸  Processing IMG_0026.JPG\n","   âœ”ï¸  3 boxes\n","   ğŸ’¾ Saved â†’ IMG_0026.JPG (success=True)\n","â–¶ï¸  Processing IMG_0027.JPG\n","   âœ”ï¸  2 boxes\n","   ğŸ’¾ Saved â†’ IMG_0027.JPG (success=True)\n","â–¶ï¸  Processing IMG_0028.JPG\n","   âœ”ï¸  5 boxes\n","   ğŸ’¾ Saved â†’ IMG_0028.JPG (success=True)\n","â–¶ï¸  Processing IMG_0029.JPG\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-3225461196>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# â”€â”€ inference â”€â”€\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mn\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   âœ”ï¸  {n} boxes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m     def track(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m             )\n\u001b[1;32m    319\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_predict_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_predict_batch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim0s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    460\u001b[0m                         \u001b[0mim0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2BGR\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert image to BGR nparray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m                     \u001b[0mim0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2_flag\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# BGR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mim0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Image Read Error {path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/patches.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(filename, flags)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mim\u001b[0m  \u001b[0;31m# Always ensure 3 dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# 0) Force-remount and confirm\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","print(\"âœ… Drive mounted!\\n\")\n","\n","import sys, time\n","from ultralytics import YOLO\n","import cv2\n","from pathlib import Path\n","\n","# 1) Paths & sanity checks\n","BASE       = Path(\"/content/drive/MyDrive/ASCAM/Running_Code\")\n","WEIGHTS    = BASE / \"weights.pt\"\n","INPUT_DIR  = BASE / \"running_code_images\"\n","OUTPUT_DIR = BASE / \"running_code_results\"\n","\n","print(\"ğŸ” Checking your directoriesâ€¦\")\n","print(\" BASE exists?       \", BASE.exists())\n","print(\" Weights file exists?\", WEIGHTS.exists())\n","print(\" test_images exists? \", INPUT_DIR.exists())\n","if INPUT_DIR.exists():\n","    print(\"  â†’ contains:\", sorted([p.name for p in INPUT_DIR.iterdir()]))\n","print(\" test_results exists? \", OUTPUT_DIR.exists(), \"\\n\")\n","\n","if not BASE.exists() or not WEIGHTS.exists() or not INPUT_DIR.exists():\n","    print(\"âŒ One of the key paths is missing. Fix your paths and re-run.\", file=sys.stderr)\n","    sys.exit(1)\n","\n","OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# 2) Load the model (this can take 5â€“10s for a large YOLO file)\n","print(\"â³ Loading model from\", WEIGHTS)\n","t0 = time.time()\n","model = YOLO(str(WEIGHTS))\n","print(f\"âœ… Model loaded in {time.time() - t0:.1f}s\\n\")\n","\n","# 3) Inference settings\n","CONF_THRES = 0.02    # 2%\n","IOU_THRES  = 0.30    # 60%\n","MAX_DET    = 1000\n","\n","# 4) Loop!\n","for img_path in sorted(INPUT_DIR.glob(\"*.*\")):\n","    print(f\"â–¶ï¸  Processing {img_path.name}\")\n","    bgr = cv2.imread(str(img_path))\n","    if bgr is None:\n","        print(\"   âœ–ï¸  cv2.imread failed\", file=sys.stderr)\n","        continue\n","\n","    # optional: show the shape so you know it was read\n","    print(\"   image shape:\", bgr.shape)\n","\n","    # Perform prediction (verbose=True will show you the CLI-style summary)\n","    results = model.predict(\n","        source=str(img_path),\n","        conf=CONF_THRES,\n","        iou=IOU_THRES,\n","        max_det=MAX_DET,\n","        verbose=False\n","    )[0]\n","\n","    n = len(results.boxes)\n","    print(f\"   âœ”ï¸  {n} boxes after NMS (confâ‰¥{CONF_THRES*100:.0f}%)\")\n","\n","    if n == 0:\n","        continue\n","\n","# â”€â”€â”€ Drawing parameters â”€â”€â”€\n","BOX_COLOR       = (0, 0, 255)            # Red in BGR\n","BOX_THICKNESS   = 10                      # 4px thick\n","FONT            = cv2.FONT_HERSHEY_SIMPLEX\n","FONT_SCALE    = 3.0                       # adjust as needed\n","FONT_THICK    = 8                         # text thickness\n","MARGIN        = 10                       # px from top/right edge\n","\n","# 4) Loop!\n","for img_path in sorted(INPUT_DIR.glob(\"*.*\")):\n","    print(f\"â–¶ï¸  Processing {img_path.name}\")\n","    bgr = cv2.imread(str(img_path))\n","    if bgr is None:\n","        print(\"   âœ–ï¸  cv2.imread failed\", file=sys.stderr)\n","        continue\n","\n","    # inference\n","    results = model.predict(\n","        source=str(img_path),\n","        conf=CONF_THRES,\n","        iou=IOU_THRES,\n","        max_det=MAX_DET,\n","        verbose=False\n","    )[0]\n","\n","    n = len(results.boxes)\n","    print(f\"   âœ”ï¸  {n} boxes after NMS (confâ‰¥{CONF_THRES*100:.0f}%)\")\n","\n","    if n > 0:\n","        # draw each box\n","        for box in results.boxes:\n","            x1, y1, x2, y2 = map(int, box.xyxy[0])\n","            cv2.rectangle(\n","                bgr,\n","                (x1, y1),\n","                (x2, y2),\n","                BOX_COLOR,\n","                BOX_THICKNESS\n","            )\n","\n","        # overlay â€œTotal swellings: Nâ€ in the upper-right\n","        text = f\"Total swellings: {n}\"\n","        (tw, th), _ = cv2.getTextSize(text, FONT, FONT_SCALE, FONT_THICK)\n","        text_x = bgr.shape[1] - tw - MARGIN\n","        text_y = MARGIN + th\n","        cv2.putText(\n","            bgr, text,\n","            (text_x, text_y),\n","            FONT,\n","            FONT_SCALE,\n","            BOX_COLOR,\n","            FONT_THICK,\n","            lineType=cv2.LINE_AA\n","        )\n","\n","    # save **inside** the loop for every image\n","    out_path = OUTPUT_DIR / img_path.name\n","    ok = cv2.imwrite(str(out_path), bgr)\n","    print(f\"   ğŸ’¾ Saved: {out_path.name} (success={ok})\")\n","\n","print(\"\\nğŸ‰ Done!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4EmVFwFkKxCP","executionInfo":{"status":"ok","timestamp":1749616005527,"user_tz":420,"elapsed":37690,"user":{"displayName":"sree suri","userId":"11509733818444258318"}},"outputId":"2ddf3e56-7bb7-4db6-c9ed-40774232e609"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","âœ… Drive mounted!\n","\n","ğŸ” Checking your directoriesâ€¦\n"," BASE exists?        True\n"," Weights file exists? True\n"," test_images exists?  True\n","  â†’ contains: ['IMG_0015.JPG', 'IMG_0017.JPG', 'IMG_0022.JPG', 'IMG_0023.JPG', 'IMG_0024.JPG', 'IMG_0025.JPG', 'IMG_0026.JPG', 'IMG_0027.JPG', 'IMG_0028.JPG', 'IMG_0029.JPG', 'IMG_0030.JPG', 'IMG_0031.JPG']\n"," test_results exists?  True \n","\n","â³ Loading model from /content/drive/MyDrive/ASCAM/Running_Code/weights.pt\n","âœ… Model loaded in 1.6s\n","\n","â–¶ï¸  Processing IMG_0015.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  11 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0017.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  4 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0022.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  13 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0023.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  16 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0024.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  25 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0025.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  24 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0026.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  18 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0027.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  18 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0028.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  13 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0029.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  14 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0030.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  12 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0031.JPG\n","   image shape: (3456, 5184, 3)\n","   âœ”ï¸  5 boxes after NMS (confâ‰¥2%)\n","â–¶ï¸  Processing IMG_0015.JPG\n","   âœ”ï¸  11 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0015.JPG (success=True)\n","â–¶ï¸  Processing IMG_0017.JPG\n","   âœ”ï¸  4 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0017.JPG (success=True)\n","â–¶ï¸  Processing IMG_0022.JPG\n","   âœ”ï¸  13 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0022.JPG (success=True)\n","â–¶ï¸  Processing IMG_0023.JPG\n","   âœ”ï¸  16 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0023.JPG (success=True)\n","â–¶ï¸  Processing IMG_0024.JPG\n","   âœ”ï¸  25 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0024.JPG (success=True)\n","â–¶ï¸  Processing IMG_0025.JPG\n","   âœ”ï¸  24 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0025.JPG (success=True)\n","â–¶ï¸  Processing IMG_0026.JPG\n","   âœ”ï¸  18 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0026.JPG (success=True)\n","â–¶ï¸  Processing IMG_0027.JPG\n","   âœ”ï¸  18 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0027.JPG (success=True)\n","â–¶ï¸  Processing IMG_0028.JPG\n","   âœ”ï¸  13 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0028.JPG (success=True)\n","â–¶ï¸  Processing IMG_0029.JPG\n","   âœ”ï¸  14 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0029.JPG (success=True)\n","â–¶ï¸  Processing IMG_0030.JPG\n","   âœ”ï¸  12 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0030.JPG (success=True)\n","â–¶ï¸  Processing IMG_0031.JPG\n","   âœ”ï¸  5 boxes after NMS (confâ‰¥2%)\n","   ğŸ’¾ Saved: IMG_0031.JPG (success=True)\n","\n","ğŸ‰ Done!\n"]}]}]}